{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 05:53:41.187107: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 05:53:43.659989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-07 05:53:45.687438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 05:53:45.695532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-07 05:53:45.695756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "import rake_nltk\n",
    "from rake_nltk import Metric, Rake\n",
    "\n",
    "r = Rake()\n",
    "from flashtext import KeywordProcessor\n",
    "import pytextrank\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "tqdm(tqdm())\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\n",
    "    \"/home/kareem/hacking/research/nlp_projects/repotech/Resume_Matcher/disaster_tweets/train.csv\"\n",
    ")\n",
    "data_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text   \n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...  \\\n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\n",
    "    \"/home/kareem/hacking/research/nlp_projects/repotech/Resume_Matcher/disaster_tweets/test.csv\"\n",
    ")\n",
    "data_test.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_stop_word = [\"i\", \"we\", \"are\", \"and\"]\n",
    "\n",
    "\n",
    "# SPACY LEMMA\n",
    "def spacy_lemma_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [tok.lemma_.lower().strip()\n",
    "              for tok in doc if tok.lemma_ != \"-PRON-\"]\n",
    "    tokens = [tok for tok in tokens if tok not in own_stop_word]\n",
    "    tokens = \" \".join(tokens)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Remove URL\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url.sub(r\"\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Clenaing - Done\n",
      "Text Cleaning - Done\n"
     ]
    }
   ],
   "source": [
    "data_train[\"text_clean\"] = data_train[\"text\"].apply(remove_URL)\n",
    "data_train[\"text_clean\"] = data_train[\"text\"].apply(spacy_lemma_text)\n",
    "print(\"Training Clenaing - Done\")\n",
    "data_test[\"text_clean\"] = data_test[\"text\"].apply(remove_URL)\n",
    "data_test[\"text_clean\"] = data_test[\"text\"].apply(spacy_lemma_text)\n",
    "print(\"Text Cleaning - Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapid Automatic Keyword Extraction \n",
    "**Rake** short for Rapid Automatic Keyword Extraction algorithm, is a domain independent keyword extraction algorithm which tries to determine key phrases in a body of text by analyzing the frequency of word appearance and its co-occurance with other words in the text.\n",
    "- This is used for extracting and ranking the keywords/phrases out of a document without any other \n",
    " context except for the document itself.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rake_keywords = []\n",
    "r = Rake()\n",
    "r = Rake(min_length=2, max_length=4)\n",
    "\n",
    "for text in data_train[\"text_clean\"]:\n",
    "    r.extract_keywords_from_text(text)\n",
    "    r.get_ranked_phrases()\n",
    "    Rake_keywords.append(r.get_ranked_phrases())\n",
    "data_train[\"Rake_Keyword\"] = Rake_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rake_keywords = []\n",
    "r = Rake()\n",
    "r = Rake(min_length=2, max_length=4)\n",
    "\n",
    "for text in data_test[\"text_clean\"]:\n",
    "    r.extract_keywords_from_text(text)\n",
    "    r.get_ranked_phrases()\n",
    "    Rake_keywords.append(r.get_ranked_phrases())\n",
    "\n",
    "data_test[\"Rake_Keyword\"] = Rake_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>Rake_Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deed be the reason of this # earthquake ma...</td>\n",
       "      <td>[earthquake may allah forgive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask . canada</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all resident ask to ' shelter in place ' be be...</td>\n",
       "      <td>[resident ask, place order]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive # wildfire evacuation or...</td>\n",
       "      <td>[wildfire evacuation order, 000 people receive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got send this photo from ruby # alaska as...</td>\n",
       "      <td>[wildfire pour, got send]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>two giant crane hold a bridge collapse into ne...</td>\n",
       "      <td>[two giant crane hold, nearby home http ://, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @thetawniest the out of control w...</td>\n",
       "      <td>[control wild fire, northern part, california ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>m1.94 [ 01:04 utc]?5 km s of volcano hawaii . ...</td>\n",
       "      <td>[volcano hawaii, http ://]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>police investigate after an e - bike collide w...</td>\n",
       "      <td>[life threaten injury, police investigate, lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>the late : more home raze by northern californ...</td>\n",
       "      <td>[abc news http ://, northern california wildfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_clean   \n",
       "0     our deed be the reason of this # earthquake ma...  \\\n",
       "1               forest fire near la ronge sask . canada   \n",
       "2     all resident ask to ' shelter in place ' be be...   \n",
       "3     13,000 people receive # wildfire evacuation or...   \n",
       "4     just got send this photo from ruby # alaska as...   \n",
       "...                                                 ...   \n",
       "7608  two giant crane hold a bridge collapse into ne...   \n",
       "7609  @aria_ahrary @thetawniest the out of control w...   \n",
       "7610  m1.94 [ 01:04 utc]?5 km s of volcano hawaii . ...   \n",
       "7611  police investigate after an e - bike collide w...   \n",
       "7612  the late : more home raze by northern californ...   \n",
       "\n",
       "                                           Rake_Keyword  \n",
       "0                        [earthquake may allah forgive]  \n",
       "1                                                    []  \n",
       "2                           [resident ask, place order]  \n",
       "3       [wildfire evacuation order, 000 people receive]  \n",
       "4                             [wildfire pour, got send]  \n",
       "...                                                 ...  \n",
       "7608  [two giant crane hold, nearby home http ://, b...  \n",
       "7609  [control wild fire, northern part, california ...  \n",
       "7610                         [volcano hawaii, http ://]  \n",
       "7611  [life threaten injury, police investigate, lit...  \n",
       "7612  [abc news http ://, northern california wildfi...  \n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"text_clean\", \"Rake_Keyword\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlashText \n",
    "\n",
    "    Extract keywords\n",
    "    Replace keywords\n",
    "    Case Sensitive\n",
    "    Span of keywords extracted\n",
    "    Get Extra information with keywords extracted\n",
    "    No clean name for Keywords\n",
    "    Add Multiple Keywords simultaneously\n",
    "    To Remove keywords\n",
    "    To check Number of terms in KeywordProcessor\n",
    "    To check if term is present in KeywordProcessor\n",
    "    Get all keywords in dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtext import KeywordProcessor\n",
    "\n",
    "Keyword_prodcessor = KeywordProcessor(case_sensitive=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict = {\"excaltor\": [\"exclators\", \"exclators\"]}\n",
    "Keyword_prodcessor.add_keywords_from_dict(keyword_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flash_keywords = []\n",
    "for i in data_train[\"text_clean\"]:\n",
    "    Keyword_prodcessor.extract_keywords(i)\n",
    "    Flash_keywords.append(Keyword_prodcessor.extract_keywords(i))\n",
    "data_train[\"Flash_keyword\"] = Flash_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flash_keywords = []\n",
    "for i in data_test[\"text_clean\"]:\n",
    "    Keyword_prodcessor.extract_keywords(i)\n",
    "    Flash_keywords.append(Keyword_prodcessor.extract_keywords(i))\n",
    "data_test[\"Flash_keyword\"] = Flash_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>Rake_Keyword</th>\n",
       "      <th>Flash_keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deed be the reason of this # earthquake ma...</td>\n",
       "      <td>[earthquake may allah forgive]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask . canada</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all resident ask to ' shelter in place ' be be...</td>\n",
       "      <td>[resident ask, place order]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive # wildfire evacuation or...</td>\n",
       "      <td>[wildfire evacuation order, 000 people receive]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got send this photo from ruby # alaska as...</td>\n",
       "      <td>[wildfire pour, got send]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>two giant crane hold a bridge collapse into ne...</td>\n",
       "      <td>[two giant crane hold, nearby home http ://, b...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>@aria_ahrary @thetawniest the out of control w...</td>\n",
       "      <td>[control wild fire, northern part, california ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>m1.94 [ 01:04 utc]?5 km s of volcano hawaii . ...</td>\n",
       "      <td>[volcano hawaii, http ://]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>police investigate after an e - bike collide w...</td>\n",
       "      <td>[life threaten injury, police investigate, lit...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>the late : more home raze by northern californ...</td>\n",
       "      <td>[abc news http ://, northern california wildfi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location   \n",
       "0         1     NaN      NaN  \\\n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target   \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \\\n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                             text_clean   \n",
       "0     our deed be the reason of this # earthquake ma...  \\\n",
       "1               forest fire near la ronge sask . canada   \n",
       "2     all resident ask to ' shelter in place ' be be...   \n",
       "3     13,000 people receive # wildfire evacuation or...   \n",
       "4     just got send this photo from ruby # alaska as...   \n",
       "...                                                 ...   \n",
       "7608  two giant crane hold a bridge collapse into ne...   \n",
       "7609  @aria_ahrary @thetawniest the out of control w...   \n",
       "7610  m1.94 [ 01:04 utc]?5 km s of volcano hawaii . ...   \n",
       "7611  police investigate after an e - bike collide w...   \n",
       "7612  the late : more home raze by northern californ...   \n",
       "\n",
       "                                           Rake_Keyword Flash_keyword  \n",
       "0                        [earthquake may allah forgive]            []  \n",
       "1                                                    []            []  \n",
       "2                           [resident ask, place order]            []  \n",
       "3       [wildfire evacuation order, 000 people receive]            []  \n",
       "4                             [wildfire pour, got send]            []  \n",
       "...                                                 ...           ...  \n",
       "7608  [two giant crane hold, nearby home http ://, b...            []  \n",
       "7609  [control wild fire, northern part, california ...            []  \n",
       "7610                         [volcano hawaii, http ://]            []  \n",
       "7611  [life threaten injury, police investigate, lit...            []  \n",
       "7612  [abc news http ://, northern california wildfi...            []  \n",
       "\n",
       "[7613 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect based Opinion Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_terms = []\n",
    "for review in nlp.pipe(data_train.text_clean):\n",
    "    chunks = [\n",
    "        (chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == \"NOUN\"\n",
    "    ]\n",
    "    aspect_terms.append(\" \".join(chunks))\n",
    "\n",
    "data_train[\"Aspect_Terms\"] = aspect_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_terms = []\n",
    "for review in nlp.pipe(data_test.text_clean):\n",
    "    chunks = [\n",
    "        (chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == \"NOUN\"\n",
    "    ]\n",
    "    aspect_terms.append(\" \".join(chunks))\n",
    "\n",
    "data_test[\"Aspect_Terms\"] = aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  deed reason earthquake\n",
       "1                                               fire sask\n",
       "2       resident shelter place officer evacuation shel...\n",
       "3                                            people order\n",
       "4                          photo alaska smoke pour school\n",
       "                              ...                        \n",
       "7608                                  crane collapse home\n",
       "7609                                      fire part state\n",
       "7610                                               hawaii\n",
       "7611             police collide car portugal rider injury\n",
       "7612                                                 raze\n",
       "Name: Aspect_Terms, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.Aspect_Terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Word Extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8291/349933707.py:4: DeprecationWarning: [W107] The property `Doc.is_parsed` is deprecated. Use `Doc.has_annotation(\"DEP\")` instead.\n",
      "  if review.is_parsed:\n"
     ]
    }
   ],
   "source": [
    "sentiment_terms = []\n",
    "\n",
    "for review in nlp.pipe(data_train[\"text_clean\"]):\n",
    "    if review.is_parsed:\n",
    "        sentiment_terms.append(\n",
    "            \" \".join(\n",
    "                [\n",
    "                    token.lemma_\n",
    "                    for token in review\n",
    "                    if (\n",
    "                        not token.is_stop\n",
    "                        and not token.is_punct\n",
    "                        and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\")\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        sentiment_terms.append(\"\")\n",
    "\n",
    "data_train[\"Sentiment_terms\"] = sentiment_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8291/965964425.py:4: DeprecationWarning: [W107] The property `Doc.is_parsed` is deprecated. Use `Doc.has_annotation(\"DEP\")` instead.\n",
      "  if review.is_parsed:\n"
     ]
    }
   ],
   "source": [
    "sentiment_terms = []\n",
    "\n",
    "for review in nlp.pipe(data_test[\"text_clean\"]):\n",
    "    if review.is_parsed:\n",
    "        sentiment_terms.append(\n",
    "            \" \".join(\n",
    "                [\n",
    "                    token.lemma_\n",
    "                    for token in review\n",
    "                    if (\n",
    "                        not token.is_stop\n",
    "                        and not token.is_punct\n",
    "                        and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\")\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        sentiment_terms.append(\"\")\n",
    "\n",
    "data_test[\"Sentiment_terms\"] = sentiment_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
